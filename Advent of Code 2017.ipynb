{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import requests\n",
    "import hashlib\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Functions\n",
    "For two different problems I thought I would need a BFS / DFS but didn't end up needing them.  I did however, waste a lot of time debugging them since I'm coding them from memory and they are easy to introduce subtle bugs into (at least for me). Since I'm fairly sure I'll need some search at some point, I'm just going to leave them here for future use (to be expanded as necessary, e.g. I'm not going to bother with `A*` until I need to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfs(start,goal,successors = lambda x: x):\n",
    "    frontier = collections.deque([[start]])\n",
    "    seen = set(tuple(start))\n",
    "    while frontier:\n",
    "        path = frontier.popleft()\n",
    "        node = path[-1]\n",
    "        if tuple(node) not in seen:\n",
    "            seen.add(tuple(node))\n",
    "            for s in successors(node):\n",
    "                if s == goal:\n",
    "                    return path,len(path)\n",
    "                frontier.append(path + [s])\n",
    "    return seen\n",
    "\n",
    "def dfs(start,goal,successors = lambda x: x):\n",
    "    frontier = [[start]]\n",
    "    seen = set(tuple(start))\n",
    "    while frontier:\n",
    "        path = frontier.pop()\n",
    "        node = path[-1]\n",
    "        if tuple(node) not in seen:\n",
    "            seen.add(tuple(node))\n",
    "            for s in successors(node):\n",
    "                if s == goal:\n",
    "                    return path,len(path)\n",
    "                frontier.append(path + [s])\n",
    "    return seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day One\n",
    "This should be pretty simple... for part 1 all you need to do is compare adjacent items up until the length of the list minus 1 (minus 1 because at the end, or second to last element, we compare to  i + 1).  Since I'm going for time, rather than spend the extra 30 seconds writing the code to handle when the index goes beyond the list, I just eyeballed it and saw the last element was the same as the first, and added it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day1.txt').read().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([int(x) for x,y in (zip(data, data[1:])) if x == y]) + 3 #cheated :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = len(data) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(data)):\n",
    "    ix = min(i + size,i + size - len(data))\n",
    "    if data[i] == data[ix]:\n",
    "        res.append(int(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Two\n",
    "Our input for day two is a series of rows containing tab delimited numbers, meant to mimic a spreadsheet layout.  This is straight-forward to parse by simply splitting on newlines to get the rows, and then doing a regex on each row to get numbers out, rather than dealing with the tabs. Once this is done, you still have to convert each text input to an integer in order to perform the arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = open('day2.txt').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = data2.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part one\n",
    "Part one asks us to find the difference of the minimum and maximum of each row, and then sum all of those values to calculate the \"checksum\" which will be our answer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numrows = [list(map(int,re.findall('\\d+',row))) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37923"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(max(row) - min(row) for row in numrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part two\n",
    "Part two requires us to find the only two evenly divisible items in each row, calculate the value of this division, and then sum the results.  Itertools to the rescue.... I'll just get all combinations of size 2 for each row and test divisibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(max(x,y) / min(x,y) for row in numrows \n",
    "                        for x,y in itertools.combinations(row,2) \n",
    "                        if max(x,y) % min(x,y) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 \n",
    "The minute I read this puzzle I may have mumbled a few choice words to myself.  I've seen something similar before on project euler and punted on it, because I'm not particularly great at the more \"mathy\" or number theory-esque problem types.  But, since this is Advent of Code, and I'm fully committed to at least doing my very best to solve all 25 days, I'm gonna have to buckle down and try to figure it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "This is my WIP for part one, I havent even gotten to part two.  Day four has come and gone and was fortunately way easiser. I'm still mulling this over and trying to find a solution without looking at others because I feel I'm getting close since I've found the recurrence relation, I just need to figure out how to use that to calculate the distance to the target.\n",
    "\n",
    "<strong>UPDATE</strong>: After basically an entire day of kicking around ideas and ironing out some bugs, I got a working solution for part 1, a bit before day 5 was released.  The code is most likely overly complicated which tends to be the case when I don't have a clear idea how to solve a problem and I'm just iteratively building on ideas until I get to a solution.  Below the solutions to part one and two are some properties I found which I had originally hoped to use to solve part one (a recurrence relation) but in the end couldn't figure out how to get a solution using this approach.\n",
    "\n",
    "I was a bit nervous on what part two was going to be like since most people seemed to think that was much more difficult than the first part, but it turned out to be fairly straight-foward to extend my part one code to solve part two.  I guess I got lucky in the way I implemented part one - my guess is a lot of people found a nice analytical solution to part one and then had to scrap and start from nothing for part two.  My lack of math skills saved me from the same folly since I basically had constructed the grid already in part one, which made part two much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "loc = [0,0]\n",
    "target = 265149\n",
    "MOVES = [[0,1],[-1,0],[0,-2],[2,0],[0,2]]\n",
    "INCREMENTS = [[0,0],[-2,0],[0,-2],[2,0],[0,2]]\n",
    "moves_so_far = 1\n",
    "\n",
    "def vector_process(v1,v2,func=lambda x,y: x+y):\n",
    "    return [func(a,b) for a,b in zip(v1,v2)]\n",
    "\n",
    "def move(loc,move,moves_so_far):\n",
    "    new_loc = vector_process(loc,move)\n",
    "    moves_so_far += sum([abs(num) for num in move])\n",
    "    return new_loc,moves_so_far\n",
    "\n",
    "def manhattan_distance(c1,c2):\n",
    "    return sum(vector_process(c1,c2,func=lambda x,y: abs(x-y)))\n",
    "\n",
    "def cumulative_move_steps(move):\n",
    "    x,y = move \n",
    "    moves = []\n",
    "    if x < 0:\n",
    "        for i in range(-1,x-1,-1):\n",
    "            moves.append([-1,y])\n",
    "    elif x > 0:\n",
    "        for i in range(1,x+1):\n",
    "            moves.append([1,y])\n",
    "    elif y < 0:\n",
    "        for i in range(-1,y-1,-1):\n",
    "            moves.append([x,-1])\n",
    "    elif y > 0:\n",
    "        for i in range(1,y+1):\n",
    "            moves.append([x,1])\n",
    "    return moves\n",
    "\n",
    "def part1():\n",
    "    global MOVES,loc,moves_so_far\n",
    "    while True:\n",
    "        for m in MOVES:\n",
    "            for c in cumulative_move_steps(m):\n",
    "                loc,moves_so_far = move(loc,c,moves_so_far)\n",
    "                if moves_so_far >= target:\n",
    "                    return manhattan_distance(loc,[0,0])\n",
    "        MOVES =  [vector_process(m[0],m[1]) \n",
    "                  for m in zip(MOVES,INCREMENTS)]\n",
    "\n",
    "\n",
    "def make_grid(row,col):\n",
    "    return [[0 for i in range(col)] for j in range(row)]\n",
    "print(part1())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266330\n"
     ]
    }
   ],
   "source": [
    "def part2(grid):\n",
    "    MOVES = [[0,1],[-1,0],[0,-2],[2,0],[0,2]]\n",
    "    cur_number = 1\n",
    "    grid_size = len(grid)\n",
    "    center_x,center_y = loc = [grid_size // 2] * 2\n",
    "    grid[center_x][center_y] = 1\n",
    "    def move(loc,move,cur_number):\n",
    "        new_loc = vector_process(loc,move)\n",
    "        cur_number = sum(grid[x][y] for x,y in neighbors(new_loc))\n",
    "        return new_loc,cur_number\n",
    "    def neighbors(loc):\n",
    "        return [vector_process(loc,(i,j)) for i in range(-1,2)\n",
    "                                          for j in range(-1,2) \n",
    "                                          if (0 <= i + loc[0] < grid_size and 0 <= j + loc[1] < grid_size)\n",
    "                                          and (i,j) != (0,0)]\n",
    "    while True:\n",
    "        for m in MOVES:\n",
    "            for c in cumulative_move_steps(m):\n",
    "                loc,cur_number = move(loc,c,cur_number)\n",
    "                grid[loc[0]][loc[1]] = cur_number\n",
    "                if cur_number > target:\n",
    "                    return cur_number\n",
    "        MOVES =  [vector_process(m[0],m[1]) \n",
    "                  for m in zip(MOVES,INCREMENTS)]\n",
    "\n",
    "\n",
    "print(part2(make_grid(515,515)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following were my original attempts at solving the puzzle before I threw in the towel and slept on it.  The next day I still could'nt figure out how to use these to solve part 1 so I just caved and chose to build the grid as seen above.  I still got some satisfaction out of going through this exercise since I always have been fascinated by recursion and find recursive solutions are typically very elegant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diags = [3,9,7,5]\n",
    "lrud =  [2,4,6,8]  \n",
    "\n",
    "def gen_spiral(n,target = target):\n",
    "    n = n\n",
    "    d = n - 1\n",
    "    steps = 1\n",
    "    nums = [n]\n",
    "    while n < target:\n",
    "        d += 8\n",
    "        n += d\n",
    "        steps += 1\n",
    "        nums.append(n)\n",
    "    return nums\n",
    "    \n",
    "for d in diags:\n",
    "    spirals = gen_spiral(d)\n",
    "    if target in spirals:\n",
    "        print(spirals.index(target) * 2)\n",
    "        break\n",
    "for x in lrud:\n",
    "    spirals = gen_spiral(x)\n",
    "    if target in spirals:\n",
    "        print(spirals.index(target))\n",
    "        break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 19, 40, 69, 106, 151, 204, 265, 334, 411]\n"
     ]
    }
   ],
   "source": [
    "print(gen_spiral(6)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 47, 78, 117, 164, 219, 282, 353, 432, 519]\n"
     ]
    }
   ],
   "source": [
    "def gen_spiral(n,prevn):\n",
    "    yield n\n",
    "    d = n - prevn + 8\n",
    "    n += d\n",
    "    if n < target: yield from gen_spiral(n,n-d)\n",
    "\n",
    "print(list(gen_spiral(24,9))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9, 25, 49, 81, 121, 169, 225, 289, 361]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spiral(n):\n",
    "    return 1 if n <= 0 else 2 * spiral(n-1) - spiral(n-2) + 8\n",
    "\n",
    "list(map(spiral,range(0,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4\n",
    "Here the input is a colleciton of strings delimited by newlines.  Within each string, or \"phrase\", we need to see if there are any duplicates and filter those out, and then count the remaining \"phrases\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day4.txt').read().strip()\n",
    "words = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "valid = [phrase for phrase in words if len(set(phrase.split())) == len(phrase.split())]\n",
    "print(len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "To get anagrams of a word I just found all permutations of the word in question, and then checked the rest of the list for each permutation.  This can be wasteful since you end up calculating unnecessary permutations - for example, if your list is \n",
    "\n",
    "['Christian','Christina']\n",
    "\n",
    "Only the last two letters have changed, so you should not consider any permutations where any of the first seven letters differ.  You can do this by creating a list of valid prefixes of your candidates, and making sure to not progress along the permutaitons unless your current permutation is seen in that candidate prefix list.  \n",
    "\n",
    "Because the amount of data I'm dealing with is small, and I am trying to move quickly, I'm not going to prematurely optimize and just brute force it by calculating all permutations, regardless of whether or not they are potentially invalid early on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anagrams(word):\n",
    "    return {''.join(a) for a in (itertools.permutations(word))}\n",
    "\n",
    "def anagram_found(text):\n",
    "    words = text.split()\n",
    "    for i in range(len(words) - 1):\n",
    "        for a in anagrams(words[i]):\n",
    "            if a in words[i+1:]:\n",
    "                return True\n",
    "    return False     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not(anagram_found('abcde fghij')))\n",
    "assert(anagram_found('abcde xyz ecdab'))\n",
    "assert(not(anagram_found('a ab abc abd abf abj')))\n",
    "assert(not(anagram_found('iiii oiii ooii oooi oooo')))\n",
    "assert(anagram_found('oiii ioii iioi iiio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = [phrase for phrase in words if not(anagram_found(phrase))]\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5\n",
    "Day 5 reminds me of some of the problems from last year where you had to build a mini interpreter for a limited set of machine instructions, but on a smaller scale.  The instructions turned out to be fast enough without trying to find a patterm or optimizing the sequence by some form of pre-processing, but I wouldn't be surprised if, like last year, later puzzles build on the sequence and make it prohibitively slow without performing some optmizations.  \n",
    "\n",
    "As presented, it's fairly easy to solve using some globals to keep state, and just bailing once the position is outside of the list.  I do wonder how I'll approach this in a more functional style, since I'm trying to do all of these problems in Clojure once I've finished them in Python first.  Typically whenever I think `while` in an imperative language, I think `reduce` or recursion in a functional language, so I'll probably start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day5.txt').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381680\n"
     ]
    }
   ],
   "source": [
    "nums = [int(x) for x in data]\n",
    "pos = 0\n",
    "cnt = 0\n",
    "while pos in range(len(nums)):\n",
    "    offset = nums[pos]\n",
    "    nums[pos] += 1\n",
    "    pos += offset\n",
    "    cnt += 1\n",
    "print(cnt)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29717847\n"
     ]
    }
   ],
   "source": [
    "nums = [int(x) for x in data] #rebuild nums since we mutated it in step 1\n",
    "pos = 0\n",
    "cnt = 0\n",
    "while pos in range(len(nums)):\n",
    "    offset = nums[pos]\n",
    "    if offset >= 3:\n",
    "        nums[pos] -=1\n",
    "    else:\n",
    "        nums[pos] +=1\n",
    "    pos += offset\n",
    "    cnt += 1\n",
    "print(cnt)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6\n",
    "This puzzle involves taking a sequence of numbers, or \"memory banks\", each of which has \"n\" blocks.  We are asked to find how many cycles it takes until any sequence is seen a second time, where a cycle is defined as follows:\n",
    "- find the maximum of the sequence, ties are by the first seen (lowest index)\n",
    "- reduce the blocks at this location to zero, and spread that amount over all of the subsequent banks (list elements), wrapping around once the end is hit.\n",
    "- return the number of cycles that have occured once a repeat is hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = [10,3,15,10,5,15,5,15,9,2,5,8,5,2,3,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "I started down the path of a recursive solution, because that seemed the most natural to me at the time.  Just make the updates to the list, add the result to the `seen` set, and recur with an incremented count.  Except I forgot about the 1,000 depth recursion limit in Python.  I guess this is what happens when you spend too much time in Clojure lately.  I burned a good 20 minutes trying to manually increase the recursion limit using `sys.setrecursionlimit(n)` and kept getting an infuriating error `TypeError: 'int' object is not callable`.  I eventually gave up since this isn't the documented behavior and I couldn't figure out why it was failing.  In any event, I probably should not treat an iterative problem with a recursive solution in a language without tail call optmization, so I just converted the solution to a nested `while` loop instead.\n",
    "\n",
    "Here is my recursive version, which worked on the small test input and then exploded on the actual input when the limit surpassed 1,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cycle(nums,res=set(),cnt=1):\n",
    "    highest = max(nums)\n",
    "    loc = nums.index(highest)\n",
    "    nums[loc] = 0\n",
    "    while highest > 0:\n",
    "        loc += 1\n",
    "        if loc > len(nums) - 1:\n",
    "            loc =  loc % (len(nums))\n",
    "        nums[loc] += 1\n",
    "        highest -= 1\n",
    "    if tuple(nums) in res:\n",
    "        return nums,cnt\n",
    "    res.add(tuple(nums))\n",
    "    return cycle(nums,res,cnt+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here is the version I had to replace it with after giving up on changing the recursion limit (which is obviously bad form, but I had already invested time in a working solution and wanted to not burn more time by re-writing (which didn't really take that much effort in the end anyhow).  Something about this solution rubs me the wrong way, it doesn't feel that elegant but it gets the job done.  I think it's the nested while loops that are giving me that feeling.  Anyhow - when I'm trying to solve these fast I focus on just getting something working first, making it pretty comes later.  Maybe I'll clean all these up and show the first version and the second polished version when I have more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 15, 14, 13, 12, 10, 10, 9, 8, 7, 6, 4, 3, 5] 14029\n"
     ]
    }
   ],
   "source": [
    "nums = [10,3,15,10,5,15,5,15,9,2,5,8,5,2,3,6] #rebind since mutated above\n",
    "seen = set()\n",
    "cnt = 1\n",
    "while True:\n",
    "    highest = max(nums)\n",
    "    loc = nums.index(highest)\n",
    "    nums[loc] = 0\n",
    "    while highest > 0:\n",
    "        loc += 1\n",
    "        if loc > len(nums) - 1:\n",
    "            loc =  loc % (len(nums))\n",
    "        nums[loc] += 1\n",
    "        highest -= 1\n",
    "    if tuple(nums) in seen:\n",
    "        print(nums,cnt)\n",
    "        break\n",
    "    seen.add(tuple(nums))\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Here the problem is modified such that instead of finding the cycles, we find the distance between cycles.  E.G. if the first occurence was on our third cycle, and the repeat of that occurence was at the 10th cycle, the distance is seven.  The only modificaton I need to make is swapping out my `seen` set for a dictionary, with the key as the actual sequence (tuple so it's hashable), and the value as the cycle it occured in.  On repeat I just find the current count minus the previous count, which i look up using the current sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 15, 14, 13, 12, 10, 10, 9, 8, 7, 6, 4, 3, 5] 2765\n"
     ]
    }
   ],
   "source": [
    "nums = [10,3,15,10,5,15,5,15,9,2,5,8,5,2,3,6] #rebind since mutated above\n",
    "seen = dict()\n",
    "cnt = 1\n",
    "while True:\n",
    "    highest = max(nums)\n",
    "    loc = nums.index(highest)\n",
    "    nums[loc] = 0\n",
    "    while highest > 0:\n",
    "        loc += 1\n",
    "        if loc > len(nums) - 1:\n",
    "            loc =  loc % (len(nums))\n",
    "        nums[loc] += 1\n",
    "        highest -= 1\n",
    "    if tuple(nums) in seen:\n",
    "        print(nums,cnt - seen[tuple(nums)])\n",
    "        break\n",
    "    seen[tuple(nums)] = cnt\n",
    "    cnt += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Seven\n",
    "This puzzle is about trees and recursion - two things that typically go well together.  We are given a tree in the form of an adjacency list, but we don't know where the root of the tree is - our task is to find it.  Typically when traversing a tree, you start at the root and either recursively evaluate children (for depth first search), or maintain a queue and evaluate children left to right (for breadth first search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "\n",
    "I found this problem a little tricky - typically when working with tree or graph structures I know where I'm starting, here I had to think about how I would find that start if I didn't know.  The path I chose to go down (no pun intended) was to invert the tree, and create mappings from children-to-parents instead of the given parent-to-children structure.  This means that if the input had a parent `A -> ['B','C','C']` I would create three entires in my reverse tree for each child, all of which mapped to the parent value `A`.  \n",
    "\n",
    "Once that's done, I picked a random node ('dzzbkv' below) and started working my way up the parents, until their weren't any.  I have a feeling this might not be the best way to solve it, but it worked for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day7.txt').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = [re.findall('\\w+',node) for node in data]\n",
    "tree = {n[0]:n[2:] for n in nodes}\n",
    "reverse_tree = collections.defaultdict(list)\n",
    "for k,v in tree.items():\n",
    "    for node in v:\n",
    "        reverse_tree[node].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hlhomy'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def traverse(tree,start='dzzbvkv'):\n",
    "    \"\"\"pick a random start in the reversed tree, continue until nowhere to go\"\"\"\n",
    "    if tree[start]:\n",
    "        for n in tree[start]:\n",
    "            return traverse(tree,n)\n",
    "    return start\n",
    "traverse(reverse_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Part two is tricky for me - it's still tree traversal, but you now have to incorporate the \"weights\" present at each node.  The way you incorporate them takes a bit of explaining so rather than regurgitate it here, just read the instructions on Advent of Code.\n",
    "\n",
    "In short, however, the idea is to make sure that the cumulative values of each child node of a parent are all equal, and therefore the parent is balanced.  One node is not balanced, and we need to find what it's value should be in order to make it balanced. Cumulative means that a node's value is the sum of it's children's values, plus it's own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1571 66 1505\n",
      "22313 6292 16021\n",
      "111630 111573 57\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "data = open('day7.txt').read().strip().split('\\n')\n",
    "tree = [[list(re.match('(\\w+) \\((\\d+)\\)',x[0]).groups()),x[1:]]\n",
    "        for x in [line.split('->') for line in data]]\n",
    "\n",
    "new_tree = {}\n",
    "\n",
    "for node, neighbors in tree:\n",
    "    val = int(node.pop())\n",
    "    if neighbors:\n",
    "        neighbors = [n.strip() for n in neighbors[0].strip().split(',')]\n",
    "    new_tree[node[0]] = [val, neighbors]\n",
    "\n",
    "root = 'hlhomy'\n",
    "\n",
    "def traverse(tree,node=root):\n",
    "    __, children = tree[node]\n",
    "    if not children: \n",
    "        return __\n",
    "    for c in children:\n",
    "        val, children = tree[node]\n",
    "        # if found: return \n",
    "        tree[node][0] = traverse(tree,c) + val\n",
    "    __ , children = tree[node]\n",
    "    cvals = [tree[c][0] for c in children]\n",
    "    if len(set(cvals)) == 1:\n",
    "        return tree[node][0]\n",
    "    else:\n",
    "        unbalanced_value   = [c for c in cvals if cvals.count(c) == 1][0]\n",
    "        val_it_should_be   = [c for c in cvals if cvals.count(c) != 1][0]\n",
    "        unbalanced_node    = [c for c in children if tree[c][0] == unbalanced_value][0]\n",
    "        __, unbalanced_nodes_children = tree[unbalanced_node]\n",
    "        unbalanced_node_values = [tree[c][0] for c in unbalanced_nodes_children]\n",
    "        val_to_balance  = val_it_should_be - sum(unbalanced_node_values)\n",
    "        print(val_it_should_be,sum(unbalanced_node_values),val_to_balance)\n",
    "        return  val_to_balance\n",
    "\n",
    "print(traverse(new_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Eight\n",
    "Another mini-interpreter style problem.  This one is easy to parse, and the instructions are fairly limited.  I am almost certain we'll see a similar puzzle later with more involved parsing, and a greater set of operations to choose from.  Part 1 and 2 are both really solved by the same piece of code below, the only difference is that part 1 asks for the maximum register value *after* all instructions have run, while part 2 asks for the maximum value ever seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day8.txt').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instructions = [re.match('(\\w+) (inc|dec) (-*\\d+) if (.*)',instr).groups() for instr in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "registers = {instr[0]:0 for instr in instructions}\n",
    "\n",
    "def process_expr(expr):\n",
    "    reg, test, val = expr.split(' ')\n",
    "    reg_val = registers[reg]\n",
    "    expr = (''.join(str(reg_val) + test  + str(val)))\n",
    "    return eval(expr)\n",
    "\n",
    "greatest_so_far = 0\n",
    "\n",
    "for reg,op,val,expr in instructions:\n",
    "    current_reg_val = registers[reg]\n",
    "    if process_expr(expr):\n",
    "        if op == 'inc':\n",
    "            registers[reg] = current_reg_val + int(val)\n",
    "        else:\n",
    "            registers[reg] = current_reg_val - int(val)\n",
    "    current_highest_val = max(registers.values())\n",
    "    if current_highest_val > greatest_so_far:\n",
    "        greatest_so_far = current_highest_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6696\n"
     ]
    }
   ],
   "source": [
    "print(greatest_so_far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Processing the instruction set and making the indicated modifications to the registers results in solving both problems at once - although I didn't know this until I read part two.  After going through all the instructions and changing the register values, part one is just the max of the register values, and the only change I needed to make for part two was adding the global `greatest_so_far` and the `if current_highest_val > greatest_so_far` test at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061\n"
     ]
    }
   ],
   "source": [
    "print(max(registers.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day Nine\n",
    "I'm noticing a theme here... lot's of recursion and interpreters.  I tried to use recursion but got bit again by python's limit sinc the input text is much larger than 1,000, and had to re-write to some nested while loops, yet again.  I included the recursive version below anyhow, since I had already buit it on the tests cases before figuring out the input was too large for it to work.\n",
    "\n",
    "Part one and two are both solved below, there is only a slight modification for part two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day9.txt').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tests pass'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_stream(s,val=1,garbage=False):\n",
    "    if not s: return 0\n",
    "    first, rest = s[0], s[1:]\n",
    "    if first == '{':\n",
    "        if not garbage:\n",
    "            return val + process_stream(rest,val + 1,garbage)\n",
    "        else:\n",
    "            return process_stream(rest,val,garbage)\n",
    "    elif first == '}':\n",
    "        if not garbage:\n",
    "            return process_stream(rest, val - 1,garbage)\n",
    "        else:\n",
    "            return process_stream(rest, val,garbage)\n",
    "    elif first == '!':\n",
    "        return process_stream(rest[1:],val,garbage)\n",
    "    elif first == '<':\n",
    "        return process_stream(rest,val,garbage=True)\n",
    "    elif first == '>':\n",
    "        return process_stream(rest,val,garbage=False)\n",
    "    else:\n",
    "        return process_stream(rest,val,garbage)\n",
    "        \n",
    "def test():\n",
    "    \"\"\"These work given the small input size, but for larger inputs it doesn't.\"\"\"\n",
    "    assert(process_stream('{}') == 1)\n",
    "    assert(process_stream('{{{}}}') == 6)\n",
    "    assert(process_stream('{{},{}}') == 5)\n",
    "    assert(process_stream('{{{},{},{{}}}}') == 16)\n",
    "    assert(process_stream('{<a>,<a>,<a>,<a>}') == 1)\n",
    "    assert(process_stream('{{<ab>},{<ab>},{<ab>},{<ab>}}') == 9)\n",
    "    assert(process_stream('{{<!!>},{<!!>},{<!!>},{<!!>}}') == 9)\n",
    "    assert(process_stream('{{<a!>},{<a!>},{<a!>},{<ab>}}') == 3)\n",
    "    return \"tests pass\"\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass.\n"
     ]
    }
   ],
   "source": [
    "def process_stream_non_recursive(s,part=1):\n",
    "    \"\"\"translation of above to an iterative form (avoid using stack)\"\"\"\n",
    "    val = 0\n",
    "    ix = 0\n",
    "    totals = []\n",
    "    garbage_count = 0\n",
    "    while ix < len(s):\n",
    "        if s[ix] == '{':\n",
    "            val += 1\n",
    "            totals.append(val)\n",
    "        elif s[ix] == '}':\n",
    "            val -= 1\n",
    "        elif s[ix] == '<':\n",
    "            ix += 1\n",
    "            while ix < len(s):\n",
    "                if s[ix] == '!':\n",
    "                    ix += 2\n",
    "                elif s[ix] == '>':\n",
    "                    break\n",
    "                else:\n",
    "                    garbage_count += 1\n",
    "                    ix += 1\n",
    "        ix += 1\n",
    "    if part == 1:\n",
    "        return sum(totals) #part one\n",
    "    else:\n",
    "        return garbage_count #part two\n",
    "\n",
    "def test_day9():\n",
    "    assert(process_stream_non_recursive('{}') == 1)\n",
    "    assert(process_stream_non_recursive('{{{}}}') == 6)\n",
    "    assert(process_stream_non_recursive('{{},{}}') == 5)\n",
    "    assert(process_stream_non_recursive('{{{},{},{{}}}}') == 16)\n",
    "    assert(process_stream_non_recursive('{<a>,<a>,<a>,<a>}') == 1)\n",
    "    assert(process_stream_non_recursive('{{<ab>},{<ab>},{<ab>},{<ab>}}') == 9)\n",
    "    assert(process_stream_non_recursive('{{<!!>},{<!!>},{<!!>},{<!!>}}') == 9)\n",
    "    assert(process_stream_non_recursive('{{<a!>},{<a!>},{<a!>},{<ab>}}') == 3)\n",
    "    print(\"tests pass.\")\n",
    "test_day9()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14212"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_stream_non_recursive(data,part=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6569"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_stream_non_recursive(data,part=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Ten\n",
    "OK... this gets my vote for most obnoxious puzzle so far.  It was conceptually simple, but for me it was extremely tedious to code part 1.  I kept introducing OBO bugs and had a difficult time re-allocating the sorted array back in the main list.  Even though part 2 is considerably more involved, I found it straightforward once part 1 was out of the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = [189,1,111,246,254,2,0,120,215,93,255,50,84,15,94,62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(data=list(range(0,256)),lengths=lengths):\n",
    "    pos = 0\n",
    "    skip = 0\n",
    "    for l in lengths:\n",
    "        end = pos + l\n",
    "        if end > len(data):\n",
    "            end = end % len(data)\n",
    "            right, left = data[pos:], data[0:end]\n",
    "            all_rev = list(reversed(right+left))\n",
    "            data[pos:] = all_rev[0:len(right)]\n",
    "            data[0:end] = all_rev[len(data[pos:]):]\n",
    "        else:\n",
    "            data = data[0:pos] + list(reversed(data[pos:end])) + data[end:]\n",
    "        pos = pos + skip + l\n",
    "        if pos > len(data):\n",
    "            pos = pos % len(data)\n",
    "        skip += 1\n",
    "    return data[0] * data[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38415"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9de8846431eef262be78f590e39a4848'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringify = str(lengths)[1:-1].replace(' ','')\n",
    "to_ascii = list(map(ord,stringify)) + [17, 31, 73, 47, 23]\n",
    "\n",
    "def process(data=list(range(0,256)),lengths=to_ascii):\n",
    "    pos = 0\n",
    "    skip = 0\n",
    "    for i in range(64):\n",
    "        for l in lengths:\n",
    "            end = pos + l\n",
    "            if end > len(data):\n",
    "                end = end % len(data)\n",
    "                right, left = data[pos:], data[0:end]\n",
    "                all_rev = list(reversed(right+left))\n",
    "                data[pos:] = all_rev[0:len(right)]\n",
    "                data[0:end] = all_rev[len(data[pos:]):]\n",
    "            else:\n",
    "                data = data[0:pos] + list(reversed(data[pos:end])) + data[end:]\n",
    "            pos = pos + skip + l\n",
    "            if pos > len(data):\n",
    "                pos = pos % len(data)\n",
    "            skip += 1\n",
    "    return data\n",
    "\n",
    "knotted = process()\n",
    "xord = [knotted[i:i+16] for i in range(0,len(knotted),16)]\n",
    "xord = [reduce(lambda x, y: x ^ y, segment) for segment in xord]\n",
    "to_hex = ''.join([hex(x)[2:].zfill(2) for x in xord])\n",
    "to_hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 11\n",
    "When I read the description and provided test cases, I had no clue what was going on or how to map from directions to the provided distance test cases.  After some googling, and twitter mentions of redblob games (which I've used extensively in the past for it's ridiculously awesome graph search walk-throughs), I figured out how to move in a hex grid, and then the problem was straight-forward.\n",
    "\n",
    "That said - I still found the wording confusing.  I interprted the instructions as follows:\n",
    " - we are given a path taken by the \"child\"\n",
    " - find the end of the path, or the location the child ends up at\n",
    " - find the shortest number of steps to get to that location.\n",
    " \n",
    "Because of the \"shortest number of steps\" part, I had originally went down the path (no pun intended) of coding a Breadth First Search, after calculating the final location, to find the number of steps to that locaiton.\n",
    "\n",
    "It turns out all the problem really wanted was the distance from the start of that final location (it already is the shortest path).  You can see this by comparing the results of the BFS below vs the results of simply getting the distance of the end location from the start, or `(0,0,0)`.  They are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One & Two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day11.txt').read().strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759.0, 1501.0, [445, -759, 314])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [0,0,0]\n",
    "dirs = ['nw','n','ne','sw','s','se']\n",
    "hex_moves = [(-1,1,0),(0,1,-1),(1,0,-1),(-1,0,1),(0,-1,1),(1,-1,0)]\n",
    "coord_map = dict(zip(dirs,hex_moves))\n",
    "\n",
    "def hex_move(moves,start=(0,0,0)):\n",
    "    max_dist = 0\n",
    "    for m in moves:\n",
    "        start = vector_process(coord_map[m],start)\n",
    "        cur_dist = sum([abs(p) for p in start])/2\n",
    "        if cur_dist > max_dist:\n",
    "            max_dist = cur_dist\n",
    "    return cur_dist,max_dist,start # cur_dist = part 1, max_dist = part 2\n",
    "\n",
    "hex_move(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759\n"
     ]
    }
   ],
   "source": [
    "path, length = bfs((0,0,0),\n",
    "                   [445, -759, 314],\n",
    "                   successors=lambda x: [vector_process(m,x) for m in hex_moves])\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 12\n",
    "The input is text in the form of `a <-> [b,c,d]`, representing a bi-directional graph as an adjacency list - so `a` can go to `b,c & d`, and the reverse is also true.  We are asked to find the number of \"programs contained in the ID of 0\", which is basically asking how many unique connections, either directly or indirectly, are there to 0.  \n",
    "\n",
    "For this I'll use a DFS starting at 0 and just return the length of everything that can be visited starting from that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('day12.txt').read().strip().split('\\n')\n",
    "data = [prog.split(' <-> ') for prog in data]\n",
    "data = {int(left):list(map(int,right.split(', '))) for left, right in data}\n",
    "\n",
    "def dfs(start,successors,cnt=0,visited=set()):\n",
    "    if start not in visited:\n",
    "        visited.add(start)\n",
    "        for s in successors[start]:\n",
    "            dfs(s,successors,cnt + 1,visited)\n",
    "    return len(visited)\n",
    "            \n",
    "dfs(0,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Our twist for part two is that we want to know the total number of unique groups in the graph.  I'll just keep running dfs on every possible node and continually update a master set with all of the group sets generated by traversing each key.  I'm sure there is a better / more efficient way to do this by taking into account what's been seen and not revisiting those keys, but the dumb / brute force way worked fast enough for me, just letting the `seen` set filter out any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "def dfs(start,successors,cnt=0,visited=set()): \n",
    "    if start not in visited:\n",
    "        visited.add(start)\n",
    "        for s in successors[start]:\n",
    "            dfs(s,successors,cnt + 1,visited)\n",
    "    return visited\n",
    "\n",
    "seen = set()\n",
    "for k in data:\n",
    "    seen.add(frozenset(dfs(k,data)))\n",
    "print(len(seen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 13\n",
    "Given a series of `layer:depth` integer pairs, we interpet the input as a firewall through which we need to move a packet, while avoiding \"scanners\".  A single line of input could be 3:5 meaning the third layer of the firewall has a depth of 5.  At each \"picosecond\" scanners move down one step until they hit the bottom depth, and then they move back up one step until they hit the top, oscillating up and down like an elevator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "Given the complete firewall, composed of many layer:depth units, we need to find the number of times a packet attempts to *enter* a layer which has a scanner present.  Packets move only along the top of each layer (depth 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1844"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('day13.txt').read().strip().split('\\n')\n",
    "firewalls = [(int(d),'fwd',['s'] + list(range(int(r) - 1))) \n",
    "             for (d,r) in [line.split(': ') for line in data]]\n",
    "\n",
    "valid_depths = {d for d,dr,r in firewalls}\n",
    "missing_depths = set(range(max(valid_depths) + 1)) - valid_depths\n",
    "fill_in_missing = [(m,'fwd', ['e']) for m in sorted(missing_depths)]\n",
    "all_together = sorted(fill_in_missing + firewalls,key = lambda x: x[0])\n",
    "\n",
    "def elevator(coll,n,ix,dr):\n",
    "    while n > 0:\n",
    "        if dr == 'fwd':\n",
    "            ix += 1\n",
    "            if ix > len(coll) - 1:\n",
    "                ix -= 2\n",
    "                dr = 'bwd'\n",
    "        else:\n",
    "            ix -= 1\n",
    "            if ix < 0:\n",
    "                ix += 2\n",
    "                dr = 'fwd'\n",
    "        n -= 1\n",
    "    return (ix,dr)\n",
    "\n",
    "def move_scanner(depth_and_range):\n",
    "    d,dr,r = depth_and_range\n",
    "    if 'e' in r: return d,dr,r\n",
    "    loc = r.index('s')\n",
    "    r[loc] = '*'\n",
    "    new_loc,dr = elevator(r,1,loc,dr)\n",
    "    r[new_loc] = 's'\n",
    "    return d,dr,r\n",
    "\n",
    "penalty = []\n",
    "for i in range(len(all_together)):\n",
    "    d,dr,r = all_together[i]\n",
    "    if r[0] == 's':\n",
    "        penalty.append(d * len(r))\n",
    "    all_together = list(map(move_scanner,all_together))\n",
    "\n",
    "sum(penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'fwd', ['*', '*', '*', 's']),\n",
       " (1, 'fwd', ['*', 's']),\n",
       " (2, 'bwd', ['*', 's', '*']),\n",
       " (3, 'fwd', ['e']),\n",
       " (4, 'fwd', ['*', '*', '*', 's'])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_together[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two (and improved part one)\n",
    "I knew there was a simple way using modulo to do the elevator movements, but it just wasn't coming to me when I first tried the puzzle.  The next morning a coworker hinted at the modulo math required to tell if a scanner was at the top, and once I had that, the puzzle became infinitely simpler.  I'm including the original solution to part one (I could easily extend this for part two - at least I think I could) to keep myself honest, since I had a pretty big hint to arrive at the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844\n",
      "3897604\n"
     ]
    }
   ],
   "source": [
    "data = [list(map(int,re.findall('\\d+',line)))\n",
    "        for line in open('day13.txt').read().strip().split('\\n')]\n",
    "\n",
    "fwalls = {layer:depth for layer,depth in data}\n",
    "fwalls_inc_missing = [(layer, fwalls.get(layer,0)) for layer in range(99)]\n",
    "\n",
    "def is_at_top(i,depth):\n",
    "    return i % ((depth - 1) * 2) == 0\n",
    "\n",
    "part1 = sum(l*d if is_at_top(l,d) else 0 for l,d in fwalls_inc_missing)\n",
    "print(part1)\n",
    "\n",
    "# part 2\n",
    "picosecond = 0\n",
    "safe = False\n",
    "while not safe:\n",
    "    safe = not(any(is_at_top(picosecond + layer,depth) \n",
    "                   for layer,depth in fwalls.items()))\n",
    "    if safe:\n",
    "        print(picosecond)\n",
    "        break\n",
    "    picosecond += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8222\n"
     ]
    }
   ],
   "source": [
    "salt = 'amgozmfv'\n",
    "\n",
    "def hex_to_bin(hex_digits):\n",
    "    return ''.join(map(lambda x: bin(int(x,16))[2:].zfill(4),hex_digits))\n",
    "\n",
    "def process(text,data=list(range(0,256))):\n",
    "    to_ascii = list(map(ord,text)) + [17, 31, 73, 47, 23]\n",
    "    pos = 0\n",
    "    skip = 0\n",
    "    for i in range(64):\n",
    "        for l in to_ascii:\n",
    "            end = pos + l\n",
    "            if end > len(data):\n",
    "                end = end % len(data)\n",
    "                right, left = data[pos:], data[0:end]\n",
    "                all_rev = list(reversed(right+left))\n",
    "                data[pos:] = all_rev[0:len(right)]\n",
    "                data[0:end] = all_rev[len(data[pos:]):]\n",
    "            else:\n",
    "                data = data[0:pos] + list(reversed(data[pos:end])) + data[end:]\n",
    "            pos = pos + skip + l\n",
    "            if pos > len(data):\n",
    "                pos = pos % len(data)\n",
    "            skip += 1\n",
    "    return data\n",
    "\n",
    "def knot_hash(text):\n",
    "    knotted = process(text)\n",
    "    segmented = [knotted[i:i+16] for i in range(0,len(knotted),16)]\n",
    "    xord = [reduce(lambda x, y: x ^ y, segment) for segment in segmented]\n",
    "    to_hex = ''.join([hex(x)[2:].zfill(2) for x in xord])\n",
    "    return to_hex\n",
    "              \n",
    "grid = [hex_to_bin(knot_hash(salt + '-' + str(i))) for i in range(128)]\n",
    "print(len([sq for row in grid for sq in row if sq == '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086\n"
     ]
    }
   ],
   "source": [
    "def dfs(start,goal=lambda x: x == float('inf'),successors = lambda x: x):\n",
    "    frontier = [[start]]\n",
    "    seen = set()\n",
    "    while frontier:\n",
    "        path = frontier.pop()\n",
    "        node = path[-1]\n",
    "        if tuple(node) not in seen:\n",
    "            seen.add(tuple(node))\n",
    "            for s in successors(node):\n",
    "                if goal(s):\n",
    "                    return path,len(path)\n",
    "                frontier.append(path + [s])\n",
    "    return seen\n",
    "\n",
    "def neighbors_URDL(grid,coord,is_valid_coord = lambda x: x):\n",
    "    moves = [vector_process(coord,move) for move in [(-1,0),(0,1),(1,0),(0,-1)]]\n",
    "    valid_moves = [tuple(m) for m in moves if is_valid_coord(m) \n",
    "                   and grid[m[0]][m[1]] == '1']\n",
    "    return valid_moves\n",
    "    \n",
    "def is_valid_coord(coord,xmax=128,ymax=128):\n",
    "    x,y = coord\n",
    "    return(0 <= x < xmax) and (0 <= y < ymax) \n",
    "\n",
    "def get_clusters(grid,loc):\n",
    "    return dfs(loc, successors=lambda coord: neighbors_URDL(grid,coord,is_valid_coord))\n",
    "\n",
    "seen = {frozenset()}\n",
    "for i in range(len(grid)):\n",
    "    for j in range(len(grid[i])):\n",
    "        if (i,j) not in frozenset.union(*seen) and grid[i][j] == '1': \n",
    "            seen.add(frozenset(get_clusters(grid,(i,j))))\n",
    "print(len(seen) - 1) # minus one to account for the empty set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "A = 699\n",
    "B = 124\n",
    "\n",
    "factor_a = 16807\n",
    "factor_b = 48271\n",
    "divisor = 2147483647\n",
    "\n",
    "def generator(val,factor,multiple=1):\n",
    "    while True:\n",
    "        val = val * factor % divisor\n",
    "        if val % multiple == 0:\n",
    "            yield val\n",
    "        \n",
    "def solve(runs,multa=1,multb=1):\n",
    "    ga = generator(A,factor_a,multa)\n",
    "    gb = generator(B,factor_b,multb)\n",
    "    total = 0\n",
    "    for i in range(runs):\n",
    "        a = bin(next(ga))\n",
    "        b = bin(next(gb))\n",
    "        if a[-16:] == b[-16:]:\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "print(solve(40000000,1,1))\n",
    "print(solve(5000000,4,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 16\n",
    "Permutation Promenade - just reading this had me ready to reach for itertools - but as it turns out I won't need it.  Three operations are defined: `Spin, Exchange, and Partner` - each which perform some specified swapping of the letters *a-p*.  We get a list of input moves that are parsed into their corresponding operations, and then for each move we perform that operation (re-arrangement) of the letters.  Once all 10,000 moves are processed, the order of the letters is our answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day16.txt').read().strip().split(',')\n",
    "programs = 'abcdefghijklmnop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bkgcdefiholnpmja'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spin(sx,programs):\n",
    "    x = int(sx[1:])\n",
    "    return programs[-x:] + programs[0:len(programs)-x]\n",
    "\n",
    "def exchange(xab,programs):\n",
    "    ix_a,ix_b = list(map(int,re.findall('\\d+',xab)))\n",
    "    programs[ix_a], programs[ix_b] = programs[ix_b], programs[ix_a]\n",
    "    return programs\n",
    "\n",
    "def partner(pab,programs):\n",
    "    a,b = pab[1:].split('/')\n",
    "    ix_a, ix_b = programs.index(a), programs.index(b)\n",
    "    programs[ix_a], programs[ix_b] = programs[ix_b], programs[ix_a]\n",
    "    return programs\n",
    "\n",
    "def process(moves,programs):\n",
    "    programs = list(programs)\n",
    "    for m in moves:\n",
    "        dance_move = m[0]\n",
    "        if dance_move == 'x':\n",
    "            programs = exchange(m,programs)\n",
    "        elif dance_move == 's':\n",
    "            programs = spin(m,programs)\n",
    "        elif dance_move == 'p':\n",
    "            programs = partner(m,programs)\n",
    "        else:\n",
    "            raise ValueError('no dance type found that matches!')\n",
    "    return ''.join(programs)\n",
    "\n",
    "process(data,programs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Now we do the same thing, but 1 billion times.  Brute force isn't going to work here, so I am going to check to see if there is a discernible pattern in the dance by looking for cycles.  It turns out, for my input, after 60 iterations we are back where we started.  To be more certain I should test that this pattern holds for a few more cycles of 60, but in the interest of time I just assumed it would and proceeded - thinking I'd come back and try again if it didn't hold. \n",
    "\n",
    "Since every 60 dances, we are back at the start, We can just run the dance cycles starting at the beginning, for the remainder of 1 billion divided by 60, or 40 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "abcdefghijklmnop\n"
     ]
    }
   ],
   "source": [
    "programs = 'abcdefghijklmnop'\n",
    "seen = set()\n",
    "while programs not in seen:\n",
    "    seen.add(programs)\n",
    "    programs = process(data,programs)\n",
    "\n",
    "print(len(seen))\n",
    "print(programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knmdfoijcbpghlea'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programs = 'abcdefghijklmnop'\n",
    "for x in range (1000000000%60):\n",
    "    programs = process(data,programs)\n",
    "programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 17\n",
    "Starting with 0, we step forward through a circular buffer *n* number of times, where *n* is the puzzle input.  On each iteration a value is inserted after we move forward the *n* times, and the location of this insertion becomes the current position.  If we do this 2017 times, whats the value after 2017?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971\n"
     ]
    }
   ],
   "source": [
    "steps = 303\n",
    "nums = [0]\n",
    "ix = 0\n",
    "for i in range(1,2018):\n",
    "    ix = (ix + steps) % len(nums) + 1\n",
    "    nums = nums[0:ix] + [i] + nums[ix:]\n",
    "print(nums[ix + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Now instead of 2017 times, we need to do it 50,000,000 times.  Above I was actually building up a list as I went, but below I tried that and it was far too slow - I probably should have known that before even trying, since there is some amount in excess of 50 million ^ 2 operations to make that work.  \n",
    "\n",
    "Since building up the list isn't going to work, and I was already primed by yesterday's problem to look for patterns, I figured I'd do the same here.  Sure enough - I realized that whenever `(current position + skip size) mod iteration` is zero, then we are back at the start and so naturally the next inserted number would be in after the zero.  Now all we need to do is keep track of each time that value after zero changes, and once all iterations are done, return it.  Since we are not doing any list building, slicing, or indexing, this is an order of magnitude faster than the above way of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17202899"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number after zero will shift to 'i' whenever (i + 3) % len(nums) == 0\n",
    "length = 1\n",
    "ix = 0\n",
    "steps = 303\n",
    "afterzero = None\n",
    "for i in range(1,50000001):\n",
    "    ix = (ix + steps) % length\n",
    "    if ix == 0:\n",
    "        afterzero = i\n",
    "    length += 1\n",
    "    ix += 1\n",
    "afterzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 18\n",
    "Revenge of the Assembunny ... my prediction from Day 5 has come true, more interpreter problems.  The creater put out a poll last year for people to vote on their favorite exercises and these problems were high on the list, so I'm not surprised to see more - and not sure were done yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "There are alot of instructions to handle, and some instructions can be either register contents or integer values, so there are a few edge cases to handle (similar to last year), but it's mostly straight-forward once you get all the operations down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day18.txt').read().strip().split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds = []\n",
    "all_ops =  [(op,reg,val)for op,reg,*val in [instr.split() for instr in data]]\n",
    "registers = {reg:0 for op,reg,val in all_ops if reg.isalpha()}\n",
    "\n",
    "def snd(x,_):sounds.append(registers[x])\n",
    "def set_to(x,y):registers[x] = y\n",
    "def add_to(x,y):registers[x] = registers[x] + y\n",
    "def mul(x,y):registers[x] = registers[x] * y\n",
    "def mod(x,y):registers[x] = registers[x] % y\n",
    "def rcv(x,_):return sounds[-1],'done'if x != 0 else None\n",
    "def jgz(x,y):\n",
    "    if int(registers.get(x,x)) > 0:\n",
    "        return y,'not done'\n",
    "\n",
    "get_op = {'snd':snd,\n",
    "          'set':set_to,\n",
    "          'add':add_to,\n",
    "          'mul':mul,\n",
    "          'mod':mod,\n",
    "          'rcv':rcv,\n",
    "          'jgz':jgz}    \n",
    "\n",
    "def interpret(registers):\n",
    "    pos = 0\n",
    "    while 0 <= pos < len(all_ops):\n",
    "        op,reg,val = all_ops[pos]\n",
    "        if val: \n",
    "            val = int(registers.get(val[0],val[0]))\n",
    "        else:\n",
    "            val = None\n",
    "        op = get_op[op]\n",
    "        regval = registers.get(reg,None)\n",
    "        jmp = op(reg,val)\n",
    "        if jmp:\n",
    "            a,maybe_done = jmp\n",
    "            if maybe_done == 'done':\n",
    "                return a\n",
    "            else:\n",
    "                pos += a\n",
    "                continue\n",
    "        pos += 1\n",
    "interpret(registers)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Sweet mother of god - this was up there with day 3 part 2 for me, maybe not as bad but close.  When I read the description I was thinking of co-routines or threading, but I don't have much experience with writing threaded code, and I wanted to see if I could implement it myself before reading up on co-routines and doing it that way (which is probably the \"right\" way, but I wanted to take a stab at re-inventing the wheel first).\n",
    "\n",
    "What follows is an absolute shitshow of mutability and global variables, and it took me an entire day to get it working even in it's current state.  I did have a few bugs, one of the most insidious was that I was popping off the end of my queues instead of the beginning, treating them as a stack rather than a queue.  This took a while to find and I had to resort to printing out the test inputs and tracing through step by step to see what registers were being set to, but eventually I found it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6858\n"
     ]
    }
   ],
   "source": [
    "def rcv(X,q,register): register[X] = q.pop(0) if q else register[X]\n",
    "def snd(X,q,register): q.append(int(register.get(X,X)))\n",
    "def set_(X,Y,register): register[X] = Y\n",
    "def add(X,Y,register): register[X] += Y\n",
    "def mul(X,Y,register): register[X] *= Y\n",
    "def mod(X,Y,register): register[X] %= Y\n",
    "def jgz(X,Y,register): return Y if int(register.get(X,X)) > 0 else None\n",
    "\n",
    "all_ops = {'rcv':rcv,'snd':snd,'set':set_,'add':add,'mul':mul,'mod':mod,'jgz':jgz}\n",
    "programs = [inst.split(' ') for inst in [inst for inst in data]]\n",
    "registers0 = {'a':0,'p':0,'i':0,'b':0,'f':0}\n",
    "registers1 = {'a':0,'p':1,'i':0,'b':0,'f':0}\n",
    "qs = {0:[],1:[]}\n",
    "\n",
    "envs = {\n",
    "        0: {\n",
    "            'program':0,\n",
    "            'register':registers0,\n",
    "            'pos':[0],\n",
    "            'q':qs[0],\n",
    "            'otherq':qs[1],\n",
    "            'sent':[0],\n",
    "            'finished':[False]\n",
    "           },\n",
    "\n",
    "        1: {\n",
    "            'program':1,\n",
    "            'register':registers1,\n",
    "            'pos':[0],\n",
    "            'q':qs[1],\n",
    "            'otherq':qs[0],\n",
    "            'sent':[0],\n",
    "            'finished':[False]\n",
    "           }\n",
    "        }\n",
    "           \n",
    "def interpret(program=None,register=None,pos=None,q=None,otherq=None,\n",
    "              sent=None,finished=None):\n",
    "    while 0 <= pos[0] < len(programs):\n",
    "        ## reg is envs[1]['finished'][0] - always a reg except for jnz\n",
    "        op,reg,*reg_or_val = programs[pos[0]] \n",
    "        func = all_ops[op]\n",
    "        if reg_or_val:\n",
    "            reg_or_val = reg_or_val[0]\n",
    "            val = int(register.get(reg_or_val,reg_or_val))\n",
    "            maybe_jump = func(reg,val,register)\n",
    "            if maybe_jump:\n",
    "                pos[0] += maybe_jump\n",
    "                continue\n",
    "        ## if no reg_or_val we know it's either a snd or rcv bc both only take one arg\n",
    "        elif op == 'snd':\n",
    "            func(reg,otherq,register)\n",
    "            sent[0] += 1  \n",
    "        elif op == 'rcv':\n",
    "            if not q:\n",
    "                return 'waiting'\n",
    "            else:\n",
    "                func(reg,q,register)\n",
    "        else:\n",
    "            raise ValueError('no instruction matching {}'.format(op))\n",
    "            \n",
    "        pos[0] += 1\n",
    "    finished[0] = True\n",
    "\n",
    "## each needs it's own q, register, position, and sent_times\n",
    "def run_interpreter():\n",
    "    while not (envs[0]['finished'][0] and envs[1]['finished'][0]):  \n",
    "        while not envs[0]['finished'][0]:\n",
    "            status = interpret(**envs[0])\n",
    "            if status == 'waiting':\n",
    "                break\n",
    "        while not envs[1]['finished'][0]:\n",
    "            status = interpret(**envs[1])\n",
    "            if status == 'waiting':\n",
    "                break\n",
    "        deadlocked = not(envs[0]['q']) and  not(envs[1]['q'])\n",
    "        if deadlocked: return envs[1]['sent'][0] \n",
    "    return envs[1]['sent'][0]\n",
    "print(run_interpreter())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 19\n",
    "At first when I saw the input I wasn't quite sure how to translate it to grid locations.  I was going to head down the path of converting it into a uniform `N x N` grid by padding each row with dummy characters where there was either whitespace or a cutoff from a newline that would otherwise be extended to the right.  \n",
    "\n",
    "The more I thought about it though, I realized I could just keep moving in one direction until I hit a plus - and once ou hit a plus, you only have two choices depending on which direction you were heading previously.  If you hit a plus going up or down, you can only go left or right, and vice versa - if you were going left or right, a plus means you can only go up or down.  How to determine which of the two?  I just try both and if the resulting direction isn't a valid coordinate (if it isn't a coordinate containing a non-whitespace value), then I exclude it and take the other direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One and Part Two\n",
    "Both parts are solved together here because the change required to produce part two was trivial.  Part one just asks the order you visited the letters in, part two wants to know how many moves you made in total to get them all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day19.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEZDNIVJWT\n",
      "17200\n"
     ]
    }
   ],
   "source": [
    "start = (0,data[0].index('|'))\n",
    "letters_remaining = set(re.findall('\\w',open('day19.txt').read()))\n",
    "dirs = {'d':(1,0),'u':(-1,0),'l':(0,-1),'r':(0,1)}\n",
    "valid_locations = {(i,j) for i in range(len(data)) \n",
    "                         for j in range(len(data[i])) \n",
    "                         if data[i][j] != ' '}\n",
    "\n",
    "visited = []\n",
    "heading = 'd'\n",
    "loc = start\n",
    "steps = 1\n",
    "while letters_remaining:\n",
    "    steps += 1\n",
    "    loc = vector_process(loc,dirs[heading])\n",
    "    x,y = loc\n",
    "    next_item = data[x][y]\n",
    "    if next_item in letters_remaining:\n",
    "        letters_remaining -= {next_item}\n",
    "        visited.append(next_item)\n",
    "    elif next_item == '+':\n",
    "        if heading in 'du':\n",
    "            lx,ly = left = vector_process(dirs['l'],loc)\n",
    "            if (lx,ly) in valid_locations:\n",
    "                heading = 'l'\n",
    "            rx,ry = right = vector_process(dirs['r'],loc)\n",
    "            if (rx,ry) in valid_locations:\n",
    "                heading = 'r'\n",
    "        else:\n",
    "            ux,uy = up = vector_process(dirs['u'],loc)\n",
    "            if (ux,uy) in valid_locations:\n",
    "                heading = 'u'\n",
    "            dx,dy = down = vector_process(dirs['d'],loc)\n",
    "            if (dx,dy) in valid_locations:\n",
    "                heading = 'd'\n",
    "print(''.join(visited))\n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 20\n",
    "Given a series of particles, each of which have the following attributes:\n",
    "\n",
    "- position (x,y,z)\n",
    "- velocity (x,y,z)\n",
    "- acceleration (x,y,z)\n",
    "\n",
    "We have to update the particle's properties above in a specific sequence.  Velocity is increased by acceleration, and then position is increased by velocity. Increase means simply summing the vectors respective `x,y,z` coordinates for the relevant properties.  Update all particles on each \"tick\" according to this update sequence, and once this is done, find the particle with the position vector closest to (0,0,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day20.txt').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_pva(p,v,a):\n",
    "    v = vector_process(v,a)\n",
    "    p = vector_process(v,p)\n",
    "    return (p,v,a)\n",
    "\n",
    "def parse_pva(pva):\n",
    "    parsed = re.findall(r'<(.*?)>',pva)\n",
    "    return [[int(n) for n in p.split(',')] for p in parsed]\n",
    "\n",
    "pvas = [parse_pva(d) for d in data]\n",
    "\n",
    "def ticks(pvas):\n",
    "    ## assuming that processing each particle represents a tick\n",
    "    for i in range(len(pvas)):\n",
    "        pvas = [process_pva(*tick) for tick in pvas]\n",
    "    return pvas\n",
    "\n",
    "def distance(particle):\n",
    "    p,v,a = particle\n",
    "    return sum(abs(x) for x in p)\n",
    "\n",
    "epoch = ticks(pvas)\n",
    "epoch.index(min(epoch,key=distance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "Now after each tick, if any positions collide (if any positions are the same), filter them out permanently.  After all collisions are resolved, how many particles remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ticks(pvas):\n",
    "    ## assuming that processing each particle represents a tick\n",
    "    for i in range(len(pvas)):\n",
    "        pvas = [process_pva(*tick) for tick in pvas]\n",
    "        counts = collections.Counter([tuple(p) for p,v,a in pvas])\n",
    "        pvas = [[p,v,a] for p,v,a in pvas if counts[tuple(p)] < 2]\n",
    "    return pvas\n",
    "\n",
    "pvas = [parse_pva(d) for d in data]\n",
    "epoch = ticks(pvas)\n",
    "len(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "data = open('day21.txt').read().strip().split('\\n')\n",
    "RULES = dict(d.split(' => ') for d in data)\n",
    "\n",
    "def flips(grid):\n",
    "    left_or_right = [list(reversed(row)) for row in grid]\n",
    "    up_or_down = list(reversed(grid))\n",
    "    return [left_or_right,up_or_down]\n",
    "\n",
    "def rotations(grid):\n",
    "    left_flip,down_flip = flips(grid)\n",
    "    rotations = [grid,left_flip,down_flip] \n",
    "    for i in range(len([90,180,270])):\n",
    "        tgrid = transpose(grid)\n",
    "        revt = [list(reversed(g)) for g in tgrid]\n",
    "        rotations.extend([revt,tgrid])\n",
    "        grid = revt\n",
    "    return rotations\n",
    "\n",
    "def transpose(grid):\n",
    "    return list(zip(*grid))\n",
    "\n",
    "def partition(n,coll):\n",
    "    return [coll[i:i+n] for i in range(0,len(coll),n)]\n",
    "\n",
    "def grid_to_string(grid,sep=\"\"):\n",
    "    return sep.join([\"\".join(row) for row in grid])\n",
    "\n",
    "def string_to_grid(gridstring):\n",
    "    return [list(row) for row in gridstring.split('/')]\n",
    "\n",
    "def split_grid(grid):\n",
    "    size = len(grid)\n",
    "    if size == 2 or size == 3: return [grid_to_string(grid,sep=\"/\")]\n",
    "    elif size % 2 == 0: n = 2\n",
    "    else: n = 3\n",
    "    row_slices = [partition(n,row) for row in grid]\n",
    "    row_slices_transposed = transpose(row_slices)\n",
    "    slice_again = [partition(n,row_t) for row_t in row_slices_transposed]\n",
    "    reorder = transpose(slice_again)\n",
    "    lkps = [grid_to_string(segment,sep=\"/\") \n",
    "            for row in reorder \n",
    "            for segment in row]\n",
    "    return lkps\n",
    "\n",
    "def reorientations(gridstring):\n",
    "    grid = string_to_grid(gridstring)\n",
    "    lookups = [grid_to_string(fr,sep=\"/\") for fr in rotations(grid)]\n",
    "    return lookups\n",
    "\n",
    "def find_replacement(lookups):\n",
    "    for lkp in lookups:\n",
    "        if lkp in RULES:\n",
    "            return RULES[lkp]\n",
    "    raise KeyError(\"no lkp: '{}' found in RULES.\".format(lkp)) \n",
    "\n",
    "def flatten_one(colls):\n",
    "    return [x for coll in colls for x in coll]\n",
    "\n",
    "def count_on(grid):\n",
    "    return flatten_one(grid).count('#')\n",
    "\n",
    "def join_subgrids(subgrids):\n",
    "    size = len(subgrids)\n",
    "    sqrt = int(math.sqrt(size))\n",
    "    new_grid = [] \n",
    "    if size == 1:\n",
    "        return subgrids[0]\n",
    "    else:\n",
    "        for i in range(0,size,sqrt):\n",
    "            new_grid.extend([flatten_one(row) \n",
    "                             for row in transpose(subgrids[i:i+sqrt])])\n",
    "    return new_grid\n",
    "\n",
    "def printgrid(grid): \n",
    "    for row in grid:\n",
    "        print(row)\n",
    "\n",
    "def generation(start,n):\n",
    "    grid = string_to_grid(start)\n",
    "    for i in range(n):\n",
    "        sub_grid_strings = split_grid(grid)\n",
    "        new_subgrid_strings = [find_replacement(reorientations(r)) \n",
    "                               for r in sub_grid_strings]\n",
    "        subgrids = [string_to_grid(ns) for ns in new_subgrid_strings]\n",
    "        grid = join_subgrids(subgrids)\n",
    "    return count_on(grid)\n",
    "\n",
    "print(generation(\".#./..#/###\",5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879071\n"
     ]
    }
   ],
   "source": [
    "print(generation(\".#./..#/###\",18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5223"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('day22.txt').read().strip().split('\\n')\n",
    "current_node = len(data)//2, len(data[0])//2\n",
    "infected = {(i,j) for i in range(len(data))\n",
    "                  for j in range(len(data[i]))\n",
    "                  if data[i][j] == \"#\"}\n",
    "\n",
    "moves = {'N':{'L':'W','R':'E'},\n",
    "         'S':{'L':'E','R':'W'},\n",
    "         'E':{'L':'N','R':'S'},\n",
    "         'W':{'L':'S','R':'N'}}\n",
    "\n",
    "coords = {'N':(-1,0),'S':(1,0),'E':(0,1),'W':(0,-1)}\n",
    "node_status = {}\n",
    "\n",
    "def burst(current_node,direction,bursts=10000,times_infected=0):\n",
    "    for i in range(bursts):\n",
    "        if current_node in infected:\n",
    "            turn = 'R'\n",
    "            infected.remove(current_node)\n",
    "        else:\n",
    "            turn ='L'\n",
    "            infected.add(current_node)\n",
    "            times_infected += 1\n",
    "        direction = moves[direction][turn]\n",
    "        current_node = tuple(vector_process(current_node,coords[direction]))\n",
    "    return times_infected\n",
    "    \n",
    "burst(current_node,'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2511456"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = {(i,j):'I' if data[i][j] == '#' else 'C'\n",
    "         for i in range(len(data))\n",
    "         for j in range(len(data[i]))}\n",
    "\n",
    "reverse_direction = {'N':'S','S':'N','E':'W','W':'E'}\n",
    "current_node = len(data)//2, len(data[0])//2\n",
    "\n",
    "def burst(current_node,direction,bursts=10000,times_infected=0):\n",
    "    for i in range(bursts):\n",
    "        status = nodes.get(current_node,'C')\n",
    "        if status == 'C':\n",
    "            turn = 'L'\n",
    "            direction = moves[direction][turn]\n",
    "            status = 'W'\n",
    "        elif status == 'I':\n",
    "            turn = 'R'\n",
    "            direction = moves[direction][turn]\n",
    "            status = 'F'\n",
    "        elif status == 'W':\n",
    "            times_infected += 1\n",
    "            status = 'I'\n",
    "        else:\n",
    "            direction = reverse_direction[direction]\n",
    "            status = 'C'\n",
    "        nodes[current_node] = status\n",
    "        current_node = tuple(vector_process(current_node,coords[direction]))\n",
    "    return times_infected\n",
    "\n",
    "burst(current_node,'N',bursts=10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('day23.txt').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a': 0, 'b': 57, 'c': 57, 'd': 57, 'e': 57, 'f': 0, 'g': 0, 'h': 1}, 3025)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registers = {reg:0 for reg in 'abcdefgh'}\n",
    "all_ops =  [(op,reg,val)for op,reg,*val in [instr.split() for instr in data]]\n",
    "\n",
    "def set_(x,y):registers[x] = y\n",
    "def add(x,y):registers[x] = registers[x] + y\n",
    "def sub(x,y):registers[x] = registers[x] - y\n",
    "def mul(x,y):registers[x] = registers[x] * y\n",
    "def jnz(x,y): return y if int(registers.get(x,x)) != 0 else None\n",
    "    \n",
    "get_op = {'set':set_,\n",
    "          'add':add,\n",
    "          'mul':mul,\n",
    "          'sub':sub,\n",
    "          'jnz':jnz}\n",
    "\n",
    "def interpret(pos=0):\n",
    "    mul_invoked = 0\n",
    "    while 0 <= pos < len(all_ops):\n",
    "        op,reg,val = all_ops[pos]\n",
    "        if op == 'mul':\n",
    "            mul_invoked +=1 \n",
    "        val = int(registers.get(val[0],val[0]))\n",
    "        op = get_op[op]\n",
    "        jmp = op(reg,val)\n",
    "        if jmp:\n",
    "            pos += jmp\n",
    "            continue\n",
    "        pos += 1\n",
    "    return registers,mul_invoked\n",
    "interpret() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e,f,g,h = 1,105700,122700,0,0,0,0,0\n",
    "for i in range(1001):\n",
    "    f = 1 \n",
    "    d = 2\n",
    "    for i in range(b - 2):\n",
    "        e = 2\n",
    "        if b % d == 0:\n",
    "            f = 0\n",
    "        e = b\n",
    "        d += 1\n",
    "    if f == 0:\n",
    "        h += 1\n",
    "    g -= c\n",
    "    b += 17\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('day24.txt').read().strip().split('\\n')\n",
    "sd = list(sorted(data,key=lambda x: int(x.split('/')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ports = {tuple(map(int,port.split('/'))) for port in data}\n",
    "possible_starts = {(p1,p2) for p1,p2 in ports if p1 == 0 or p2 ==0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1868"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def connections(component,ports,all_components):\n",
    "    for p in ports:\n",
    "        revp = tuple(reversed(p))\n",
    "        prev_port = component[-1]\n",
    "        if p[0] == prev_port[-1]:\n",
    "            all_components.append(component+[p])\n",
    "            connections(component + [p], ports-{p},all_components)\n",
    "        elif revp[0] == prev_port[-1]:\n",
    "            all_components.append(component+[revp])\n",
    "            connections(component + [revp], ports-{p},all_components)\n",
    "    return all_components\n",
    "\n",
    "results = []\n",
    "\n",
    "for start in possible_starts:\n",
    "    zero_first = tuple(sorted(start))\n",
    "    components = connections([zero_first],ports-{start},all_components=[[zero_first]])\n",
    "    results += components\n",
    "\n",
    "max([sum(sum(port) for port in c) for c in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1841"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longest_and_strongest(xs): return (len(xs),sum(sum(x) for x in xs))\n",
    "sorted_res = sorted(results,key = longest_and_strongest,reverse=True)\n",
    "ans = sorted_res[0]\n",
    "sum(map(lambda x: sum(x),ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2725"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "transitions = {\n",
    " 'A':{0:(1,+1,'B'),\n",
    "      1:(0,+1,'C')},\n",
    "\n",
    " 'B':{0:(0,-1,'A'),\n",
    "      1:(0,+1,'D')},\n",
    "\n",
    " 'C':{0:(1,+1,'D'),\n",
    "      1:(1,+1,'A')},\n",
    " \n",
    " 'D':{0:(1,-1,'E'),\n",
    "      1:(0,-1,'D')},\n",
    " \n",
    " 'E':{0:(1,+1,'F'),\n",
    "      1:(1,-1,'B')},\n",
    " \n",
    " 'F':{0:(1,+1,'A'),\n",
    "      1:(1,+1,'E')}\n",
    "}\n",
    "\n",
    "state = 'A'\n",
    "cursor = 0\n",
    "tape = defaultdict(int)\n",
    "steps = 12368930\n",
    "while steps > 0:\n",
    "    new_cursor,moves,state = transitions[state][tape[cursor]]\n",
    "    tape[cursor] = new_cursor\n",
    "    cursor += moves\n",
    "    steps -= 1\n",
    "sum(tape.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def state_machine(state,cursor,tape=defaultdict(int),steps=12368930):\n",
    "    curval = tape[cursor]\n",
    "    while steps > 0:\n",
    "        if state == 'A': \n",
    "            if tape[cursor] == 0:\n",
    "                tape[cursor] = 1\n",
    "                cursor += 1\n",
    "                state = 'B'             \n",
    "            else:\n",
    "                tape[cursor] = 0\n",
    "                cursor += 1 \n",
    "                state = 'C'\n",
    "        elif state == 'B': \n",
    "            if tape[cursor] == 0:\n",
    "                tape[cursor] = 0\n",
    "                cursor -= 1\n",
    "                state = 'A'\n",
    "            else:\n",
    "                tape[cursor] = 0\n",
    "                cursor += 1 \n",
    "                state = 'D'\n",
    "        elif state == 'C': \n",
    "            if tape[cursor] == 0:\n",
    "                tape[cursor] = 1\n",
    "                cursor += 1\n",
    "                state = 'D'\n",
    "            else:\n",
    "                tape[cursor] = 1\n",
    "                cursor += 1 \n",
    "                state = 'A'\n",
    "        elif state == 'D': \n",
    "            if tape[cursor] == 0:\n",
    "                tape[cursor] = 1\n",
    "                cursor -= 1\n",
    "                state = 'E'\n",
    "            else:\n",
    "                tape[cursor] = 0\n",
    "                cursor -= 1 \n",
    "                state = 'D'\n",
    "        elif state == 'E': \n",
    "            if tape[cursor] == 0:\n",
    "                tape[cursor] = 1\n",
    "                cursor += 1\n",
    "                state = 'F'\n",
    "            else:\n",
    "                tape[cursor] = 1\n",
    "                cursor -= 1 \n",
    "                state = 'B'\n",
    "        elif state == 'F': \n",
    "            if tape[cursor] == 0:\n",
    "                tape[cursor] = 1\n",
    "                cursor += 1\n",
    "                state = 'A'\n",
    "            else:\n",
    "                tape[cursor] = 1\n",
    "                cursor += 1 \n",
    "                state = 'E'\n",
    "        steps -= 1\n",
    "    return sum(tape.values())\n",
    "\n",
    "print(state_machine('A',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
